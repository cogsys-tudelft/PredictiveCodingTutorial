{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.extend([\"../\", \"./models\"])\n",
    "\n",
    "from pc_model import PCNET, train_model, test_model\n",
    "from mlp import MLP\n",
    "from cnn import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 333\n",
    "\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "    os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    torch.mps.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loaders(dataset: str):\n",
    "\n",
    "    transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465] if \"cifar10\" == dataset else [0.5],\n",
    "        std=[0.2023, 0.1994, 0.2010] if \"cifar10\" == dataset else [0.5]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    dataset_path = os.path.abspath(f'../datasets/{dataset}/dataset')\n",
    "    os.makedirs(dataset_path, exist_ok=True)\n",
    "    batch_size = 128\n",
    "\n",
    "    if \"mnist\" == dataset:\n",
    "        DatasetClass = torchvision.datasets.MNIST\n",
    "    elif \"fmnist\" == dataset:\n",
    "        DatasetClass = torchvision.datasets.FashionMNIST\n",
    "    elif \"cifar10\" == dataset:\n",
    "        DatasetClass = torchvision.datasets.CIFAR10\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported dataset.\")\n",
    "\n",
    "    train_dataset = DatasetClass(root=dataset_path, train=True, transform=transform, download=True)\n",
    "    test_dataset  = DatasetClass(root=dataset_path, train=False, transform=transform, download=True)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model, is_pc, train_loader, test_loader, epochs, optimizer, criterion, inference_lr, inference_iterations, inference_momentum):\n",
    "    device = next(model.parameters()).device\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        with tqdm(total=len(train_loader), desc=f\"Epoch {epoch + 1}/{epochs}\", leave=False) as progress_bar:\n",
    "            for inputs, labels in train_loader:\n",
    "\n",
    "                inputs = inputs.flatten(1).to(device) if inputs.shape[1:] == (1, 28, 28) else inputs.to(device)\n",
    "                labels = F.one_hot(labels, num_classes=10).float().to(device)\n",
    "                _, acc = train_model(\n",
    "                    model,\n",
    "                    inputs,\n",
    "                    labels,\n",
    "                    optimizer,\n",
    "                    criterion,\n",
    "                    inference_lr,\n",
    "                    inference_iterations,\n",
    "                    inference_momentum,\n",
    "                    pc_mode=is_pc\n",
    "                )\n",
    "                progress_bar.update(1)\n",
    "            \n",
    "            model.eval()\n",
    "            accuracies = []\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in test_loader:\n",
    "                    inputs = inputs.flatten(1).to(device) if inputs.shape[1:] == (1, 28, 28) else inputs.to(device)\n",
    "                    labels = F.one_hot(labels, num_classes=10).float().to(device)\n",
    "\n",
    "                    _, acc = test_model(model, inputs, labels, criterion)\n",
    "                    accuracies.append(acc)\n",
    "                    \n",
    "            best_accuracy = max(best_accuracy, sum(accuracies)/len(accuracies))\n",
    "            model.train()\n",
    "            print(best_accuracy, sum(accuracies)/len(accuracies))\n",
    "            \n",
    "    \n",
    "    return best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:6' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print('Available device: ', device)\n",
    "\n",
    "epochs = 25\n",
    "trials = 5\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "datasets = ['mnist', 'fmnist', 'cifar10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "\n",
    "    pc_results = []\n",
    "    bp_results = []\n",
    "\n",
    "    if dataset in ['mnist', 'fmnist']:\n",
    "        inference_lr = 0.5\n",
    "        inference_iterations = 8\n",
    "        inference_momentum = 0.8\n",
    "        generative_lr_pc = 0.0002715\n",
    "        generative_wd_pc = 0.02715\n",
    "        generative_lr_bp = 0.000275\n",
    "        generative_wd_bp = 0.00002\n",
    "\n",
    "\n",
    "    elif dataset == 'cifar10':\n",
    "        inference_lr = 0.15\n",
    "        inference_iterations = 8\n",
    "        inference_momentum = 0.35\n",
    "        generative_lr_pc = 0.0006\n",
    "        generative_wd_pc = 0.0075\n",
    "\n",
    "        generative_lr_bp = 0.00025\n",
    "        generative_wd_bp = 0.000075\n",
    "\n",
    "    train_loader, test_loader = create_loaders(dataset)\n",
    "    print(f'Comparing PC and BP on {dataset} dataset...')\n",
    "\n",
    "    for run in range(trials):\n",
    "\n",
    "        bp_model = CNN(3,10) if dataset == 'cifar10' else MLP(input_size=28*28, hidden_layers=3, hidden_size=128, output_size=10)\n",
    "        bp_model.to(device)\n",
    "        bp_optimizer = torch.optim.Adam(bp_model.parameters(), lr=generative_lr_bp, weight_decay=generative_wd_bp)\n",
    "\n",
    "        pc_model = PCNET(bp_model)\n",
    "        pc_model.to(device)\n",
    "        pc_optimizer = torch.optim.Adam(pc_model.module_dict['generative'].parameters(), lr=generative_lr_pc, weight_decay=generative_wd_pc)\n",
    "\n",
    "        start_time = time.time()\n",
    "        pc_best_accuracy = train_test(pc_model, True, train_loader, test_loader, epochs, pc_optimizer, criterion, inference_lr, inference_iterations, inference_momentum)\n",
    "        pc_training_time = time.time() - start_time\n",
    "        print(f\"Predictive Coding best accuracy: {pc_best_accuracy * 100:.2f}% - total training time: {pc_training_time:.2f} s\")\n",
    "        pc_results.append({\"run\": run + 1, \"best_accuracy\": pc_best_accuracy, \"training_time_sec\": pc_training_time})\n",
    "\n",
    "        start_time = time.time()\n",
    "        bp_best_accuracy = train_test(bp_model, False, train_loader, test_loader, epochs, bp_optimizer, criterion, 0, 0, 0)\n",
    "        bp_training_time = time.time() - start_time\n",
    "        print(f\"Backpropagation best accuracy: {bp_best_accuracy * 100:.2f}% - total training time: {bp_training_time:.2f} s\")\n",
    "        bp_results.append({\"run\": run + 1, \"best_accuracy\": bp_best_accuracy, \"training_time_sec\": bp_training_time})\n",
    "\n",
    "    pc_results = pd.DataFrame(pc_results)\n",
    "    bp_results = pd.DataFrame(bp_results)\n",
    "\n",
    "    os.makedirs(\"./results\", exist_ok=True)\n",
    "    pc_results.to_csv(f\"./results/pc_performance_{dataset}.csv\", index=False)\n",
    "    bp_results.to_csv(f\"./results/bp_performance_{dataset}.csv\", index=False)\n",
    "\n",
    "    print()\n",
    "    print(f\"{'-'*50}\")\n",
    "    print(\"Predictive Coding Performance:\")\n",
    "    print(f\"Accuracy: Mean = {pc_results['best_accuracy'].mean() * 100:.2f}%, Std = {pc_results['best_accuracy'].std() * 100:.2f}%\")\n",
    "    print(f\"Training Time: Mean = {pc_results['training_time_sec'].mean():.2f} s, Std = {pc_results['training_time_sec'].std():.2f} s\")\n",
    "\n",
    "    print(\"\\nBackpropagation Performance:\")\n",
    "    print(f\"Accuracy: Mean = {bp_results['best_accuracy'].mean() * 100:.2f}%, Std = {bp_results['best_accuracy'].std() * 100:.2f}%\")\n",
    "    print(f\"Training Time: Mean = {bp_results['training_time_sec'].mean():.2f} s, Std = {bp_results['training_time_sec'].std():.2f} s\")\n",
    "    print(f\"{'-'*50}\")\n",
    "    print(f\"{'-'*50}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in ['mnist', 'fmnist', 'cifar10']:\n",
    "    pc_results = pd.read_csv(f'./results/pc_performance_{dataset}.csv')\n",
    "    bp_results = pd.read_csv(f'./results/bp_performance_{dataset}.csv')\n",
    "\n",
    "    print(f\"\\n--- Results on {dataset.upper()} ---\")\n",
    "\n",
    "    print(\"\\nBackpropagation:\")\n",
    "    print(f\"Accuracy:     {bp_results['best_accuracy'].mean() * 100:.2f} ± {bp_results['best_accuracy'].std() * 100:.2f}%\")\n",
    "    print(f\"Train time:   {(bp_results['training_time_sec']/25).mean():.2f} ± {(bp_results['training_time_sec']/25).std():.2f} s\")\n",
    "    \n",
    "    print(\"\\nPredictive Coding:\")\n",
    "    print(f\"Accuracy:     {pc_results['best_accuracy'].mean() * 100:.2f} ± {pc_results['best_accuracy'].std() * 100:.2f}%\")\n",
    "    print(f\"Train time:   {(pc_results['training_time_sec']/25).mean():.2f} ± {(pc_results['training_time_sec']/25).std():.2f} s\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
